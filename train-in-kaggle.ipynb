{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ae3d38a",
   "metadata": {},
   "source": [
    "# CNN-LSTM Model for Anomaly Detection in Time Series Data\n",
    "\n",
    "This notebook implements a hybrid CNN-LSTM model for detecting anomalies in time series data. The model combines convolutional layers to capture local patterns with LSTM layers to capture temporal dependencies.\n",
    "\n",
    "The architecture is designed specifically for multi-sensor time series data from discharge experiments, where anomalies need to be detected as early as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "212f6612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:57:11.731871Z",
     "iopub.status.busy": "2025-05-04T17:57:11.731576Z",
     "iopub.status.idle": "2025-05-04T17:57:11.805012Z",
     "shell.execute_reply": "2025-05-04T17:57:11.804478Z",
     "shell.execute_reply.started": "2025-05-04T17:57:11.731843Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, LSTM, Dropout, Masking, GlobalMaxPooling1D, Flatten, \n",
    "    BatchNormalization, Input, Conv1D, Activation, concatenate,\n",
    "    MaxPooling1D, SpatialDropout1D, Attention, Bidirectional\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "from enum import Enum\n",
    "from typing import List, Dict, Any, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2760398f",
   "metadata": {},
   "source": [
    "## Define Data Classes and Helper Functions\n",
    "\n",
    "Define the Signal, Discharge, SignalType, and DisruptionClass classes adapted from the original implementation. Include helper functions for data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d4a03f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:57:24.501910Z",
     "iopub.status.busy": "2025-05-04T17:57:24.501348Z",
     "iopub.status.idle": "2025-05-04T17:57:24.521458Z",
     "shell.execute_reply": "2025-05-04T17:57:24.520837Z",
     "shell.execute_reply.started": "2025-05-04T17:57:24.501888Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class SignalType(Enum):\n",
    "    \"\"\"Enum for signal types.\"\"\"\n",
    "    CorrientePlasma = 1,\n",
    "    ModeLock = 2,\n",
    "    Inductancia = 3,\n",
    "    Densidad = 4,\n",
    "    DerivadaEnergiaDiamagnetica = 5,\n",
    "    PotenciaRadiada = 6,\n",
    "    PotenciaDeEntrada = 7,\n",
    "\n",
    "def get_signal_type(signal_type: int) -> SignalType:\n",
    "    \"\"\"\n",
    "    Get the signal type from an integer.\n",
    "    :param signal_type: The signal type as an integer.\n",
    "    :return: The signal type as a SignalType enum.\n",
    "    \"\"\"\n",
    "    return SignalType(signal_type) if signal_type in [s.value for s in SignalType] else None\n",
    "\n",
    "class DisruptionClass(Enum):\n",
    "    \"\"\"Enum for disruption classes.\"\"\"\n",
    "    Normal = 0,\n",
    "    Anomaly = 1,\n",
    "    Unknown = 2,\n",
    "\n",
    "class Signal:\n",
    "    \"\"\"Class representing a signal.\"\"\"\n",
    "\n",
    "    def __init__(self, label: str, times: list[float], values: list[float], signal_type: SignalType, disruption_class=DisruptionClass.Unknown):\n",
    "        \"\"\"\n",
    "        Initialize a Signal object.\n",
    "        :param label: The label of the signal. It is the file name\n",
    "        :param times: The time values of the signal.\n",
    "        :param values: The values of the signal.\n",
    "        :param signal_type: The type of the signal.\n",
    "        :param disruption_class: The class of the disruption.\n",
    "        \"\"\"\n",
    "        self.label = label\n",
    "        self.times = times\n",
    "        self.values = values\n",
    "        self.disruption_class = disruption_class\n",
    "        self.signal_type = signal_type\n",
    "        self.min = min(values) \n",
    "        self.max = max(values)\n",
    "\n",
    "    def normalize(self, min_of_its_type: Any | None, max_of_its_type: Any | None):\n",
    "        \"\"\"\n",
    "        Normalize the signal values to the range [0, 1]. Admits min and max values to normalize against them.\n",
    "        :param min_of_its_type: The minimum value of the signal type.\n",
    "        :param max_of_its_type: The maximum value of the signal type.\n",
    "        \"\"\"\n",
    "        min_val = min_of_its_type if min_of_its_type is not None else self.min\n",
    "        max_val = max_of_its_type if max_of_its_type is not None else self.max\n",
    "    \n",
    "        self.values = [(value - min_val) / (max_val - min_val) for value in self.values]\n",
    "\n",
    "class Discharge:\n",
    "    \"\"\"Class representing a discharge.\"\"\"\n",
    "\n",
    "    def __init__(self, signals: list[Signal], disruption_class=DisruptionClass.Unknown):\n",
    "        self.signals = signals\n",
    "        self.disruption_class = disruption_class\n",
    "        self.is_padded = False\n",
    "        self.is_normalized = False\n",
    "\n",
    "    def generate_similar_discharges(self, n: int):\n",
    "        similar_discharges = []\n",
    "        for _ in range(n):\n",
    "            new_signals = []\n",
    "            for signal in self.signals:\n",
    "                new_signal = Signal(signal.label, signal.times, signal.values.copy(), signal.signal_type, signal.disruption_class)\n",
    "                new_signal.values = np.random.normal(new_signal.values, 0.1).tolist()\n",
    "                new_signals.append(new_signal)\n",
    "\n",
    "            similar_discharges.append(Discharge(new_signals, self.disruption_class))\n",
    "        return similar_discharges\n",
    "    \n",
    "    def generate_windows(self, window_size: int, step: int = 1, overlap: float = 0.5):\n",
    "        \"\"\"\n",
    "        Generate windows from the signals in the discharge.\n",
    "        :param window_size: The size of each window (number of elements).\n",
    "        :param step: The step between elements within a window.\n",
    "        :param overlap: The overlap between consecutive windows (as a fraction).\n",
    "        :return: A list of discharges, each containing a list of windows\n",
    "        \"\"\"\n",
    "        windowed_discharges = []\n",
    "    \n",
    "        # Calculate how many positions we advance when collecting window_size elements with step\n",
    "        total_span = (window_size - 1) * step + 1\n",
    "        \n",
    "        # Calculate backtrack based on overlap\n",
    "        backtrack = int(total_span * overlap)\n",
    "        stride = total_span - backtrack\n",
    "        \n",
    "        # Every signal has the same length, so we can use the first one to calculate the max position\n",
    "        min_length = len(self.signals[0].values)\n",
    "        max_pos = min_length - total_span\n",
    "        \n",
    "        # Generate windows for all signals at the same positions\n",
    "        pos = 0\n",
    "        while pos <= max_pos:\n",
    "            window_signals = []\n",
    "            \n",
    "            # Create a window for each signal type at the same position\n",
    "            for signal in self.signals:\n",
    "                window_times = []\n",
    "                window_values = []\n",
    "                \n",
    "                for i in range(window_size):\n",
    "                    idx = pos + i * step\n",
    "                    window_times.append(signal.times[idx])\n",
    "                    window_values.append(signal.values[idx])\n",
    "                \n",
    "                # Create window signal of the same type\n",
    "                window = Signal(\n",
    "                    signal.label,\n",
    "                    window_times,\n",
    "                    window_values,\n",
    "                    signal.signal_type,\n",
    "                    signal.disruption_class\n",
    "                )\n",
    "                window_signals.append(window)\n",
    "            \n",
    "            # Create a discharge containing all signal types\n",
    "            windowed_discharges.append(Discharge(window_signals, self.disruption_class))\n",
    "            \n",
    "            # Move to next window start position with overlap\n",
    "            pos += stride\n",
    "        \n",
    "        return windowed_discharges\n",
    "    \n",
    "    def shape(self) -> tuple[int, int]:\n",
    "        \"\"\"\n",
    "        Get the shape of the discharge.\n",
    "        :return: The shape of the discharge as a tuple (number of signals, number of values per signal).\n",
    "        \"\"\"\n",
    "        return len(self.signals), len(self.signals[0].values) if self.signals else 0\n",
    "\n",
    "def normalize_vec(list_values: list[Signal]):\n",
    "    \"\"\"\n",
    "    Normalize a list of signals.\n",
    "    :param list_values: The list of signals to normalize.\n",
    "    \"\"\"\n",
    "    signals_normalized = []\n",
    "    min_by_type = {}\n",
    "    max_by_type = {}\n",
    "\n",
    "    for signal in list_values:\n",
    "        if signal.signal_type not in min_by_type:\n",
    "            min_by_type[signal.signal_type] = signal.min\n",
    "            max_by_type[signal.signal_type] = signal.max\n",
    "        else:\n",
    "            min_by_type[signal.signal_type] = min(min_by_type[signal.signal_type], signal.min)\n",
    "            max_by_type[signal.signal_type] = max(max_by_type[signal.signal_type], signal.max)\n",
    "\n",
    "    for signal in list_values:\n",
    "        signal.normalize(min_by_type[signal.signal_type], max_by_type[signal.signal_type])\n",
    "        signals_normalized.append(signal)\n",
    "\n",
    "    return signals_normalized\n",
    "\n",
    "def normalize(discharges: list[Discharge]) -> list[Discharge]:\n",
    "    \"\"\"\n",
    "    Normalize the signals in a list of discharges.\n",
    "    :param discharges: The list of discharges to normalize.\n",
    "    :return: The normalized discharges.\n",
    "    \"\"\"\n",
    "    all_signals = []\n",
    "    for discharge in discharges:\n",
    "        all_signals += discharge.signals\n",
    "\n",
    "    normalized_signals = normalize_vec(all_signals)\n",
    "\n",
    "    for discharge in discharges:\n",
    "        for i, signal in enumerate(discharge.signals):\n",
    "            discharge.signals[i].values = normalized_signals[i].values\n",
    "        discharge.is_normalized = True\n",
    "\n",
    "    return discharges\n",
    "\n",
    "def are_normalized(discharges: list[Discharge]) -> bool:\n",
    "    return all([discharge.is_normalized for discharge in discharges])\n",
    "\n",
    "def pad(discharges: list[Discharge]) -> list[Discharge]:\n",
    "    \"\"\"\n",
    "    Pad the signals with zeros in a list of discharges to the same length.\n",
    "    :param discharges: The list of discharges to pad.\n",
    "    :return: The padded discharges.\n",
    "    \"\"\"\n",
    "    max_length = max([len(signal.values) for discharge in discharges for signal in discharge.signals])\n",
    "    for discharge in discharges:\n",
    "        for signal in discharge.signals:\n",
    "            if len(signal.values) < max_length:\n",
    "                signal.values += [0] * (max_length - len(signal.values))\n",
    "        discharge.is_padded = True\n",
    "    return discharges\n",
    "\n",
    "def are_padded(discharges: list[Discharge]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the signals in a list of discharges are padded.\n",
    "    :param discharges: The list of discharges to check.\n",
    "    :return: True if the signals are padded, False otherwise.\n",
    "    \"\"\"\n",
    "    return all([discharge.is_padded for discharge in discharges])\n",
    "\n",
    "def get_X_y(discharges: list[Discharge]) -> tuple[list[list[float]], list[int]]:\n",
    "    \"\"\"\n",
    "    Get the X and y values from a list of discharges.\n",
    "    They are parallel lists, where X is the list of signals and y is the list of disruption classes.\n",
    "    :param discharges: The list of discharges to get the X and y values from.\n",
    "    :return: The X and y values.\n",
    "    \"\"\"\n",
    "    if not are_normalized(discharges):\n",
    "        discharges = normalize(discharges)\n",
    "    \n",
    "    X = [[signal.values for signal in discharge.signals] for discharge in discharges]\n",
    "    y = [discharge.disruption_class.value for discharge in discharges]\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Pattern for extracting sensor ID from filename\n",
    "PATTERN = \"DES_(\\\\d+)_(\\\\d+)\"\n",
    "\n",
    "def get_sensor_id(filename: str) -> str:\n",
    "    \"\"\"Extract sensor ID from signal file name\"\"\"\n",
    "    match = re.match(PATTERN, filename)\n",
    "    if match:\n",
    "        return match.group(2)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid signal file name format: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3880436d",
   "metadata": {},
   "source": [
    "## Data Loading from JSON\n",
    "\n",
    "Create functions to load discharge data from JSON files instead of receiving it via HTTP requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae905a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:57:45.304066Z",
     "iopub.status.busy": "2025-05-04T17:57:45.303357Z",
     "iopub.status.idle": "2025-05-04T17:57:45.309537Z",
     "shell.execute_reply": "2025-05-04T17:57:45.308663Z",
     "shell.execute_reply.started": "2025-05-04T17:57:45.304042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'todas menos la 70 y la 30.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m discharges\n\u001b[32m     33\u001b[39m todas_menos_la_70_y_la_30_path = \u001b[33m'\u001b[39m\u001b[33mtodas menos la 70 y la 30.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m discharges = \u001b[43mload_data_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtodas_menos_la_70_y_la_30_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mload_data_from_json\u001b[39m\u001b[34m(json_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_data_from_json\u001b[39m(json_path):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Load discharge data from a JSON file.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      6\u001b[39m         data = json.load(f)\n\u001b[32m      8\u001b[39m     discharges = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ruben\\Documents\\anomaly_detection\\py_lstm\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:326\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    321\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    322\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    323\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    324\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'todas menos la 70 y la 30.json'"
     ]
    }
   ],
   "source": [
    "def load_data_from_json(json_path):\n",
    "    \"\"\"\n",
    "    Load discharge data from a JSON file.\n",
    "    \"\"\"\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    discharges = []\n",
    "    \n",
    "    for discharge_data in data['discharges']:\n",
    "        signals = []\n",
    "        \n",
    "        for signal_data in discharge_data['signals']:\n",
    "            signals.append(\n",
    "                Signal(\n",
    "                    label=signal_data['fileName'],\n",
    "                    times=signal_data.get('times', discharge_data.get('times', [])),\n",
    "                    values=signal_data['values'],\n",
    "                    signal_type=get_signal_type(int(get_sensor_id(signal_data['fileName']))),\n",
    "                    disruption_class=DisruptionClass.Anomaly if discharge_data.get('anomalyTime') else DisruptionClass.Normal\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        discharges.append(\n",
    "            Discharge(\n",
    "                signals=signals,\n",
    "                disruption_class=DisruptionClass.Anomaly if discharge_data.get('anomalyTime') else DisruptionClass.Normal\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return discharges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468e3992",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Implement preprocessing steps including normalization, windowing, and train-test splitting. Prepare data in the correct format for the CNN-LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f039d620",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:58:38.195671Z",
     "iopub.status.busy": "2025-05-04T17:58:38.195084Z",
     "iopub.status.idle": "2025-05-04T17:58:38.202194Z",
     "shell.execute_reply": "2025-05-04T17:58:38.201366Z",
     "shell.execute_reply.started": "2025-05-04T17:58:38.195646Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(discharges, window_size=500, step=1, overlap=0.5, augment=False, augment_factor=None):\n",
    "    \"\"\"\n",
    "    Preprocess discharge data for model training:\n",
    "    1. Optional data augmentation\n",
    "    2. Windowing\n",
    "    3. Normalization\n",
    "    4. Train-test split\n",
    "    \n",
    "    Returns X_train, X_val, y_train, y_val ready for model training\n",
    "    \"\"\"\n",
    "    # Data augmentation (optional)\n",
    "    if augment and len(discharges) < 10:\n",
    "        n_discharges = len(discharges)\n",
    "        i = 0\n",
    "        while i < n_discharges:\n",
    "            d = discharges[i]\n",
    "            extended = d.generate_similar_discharges(augment_factor)\n",
    "            discharges.extend(extended)\n",
    "            i += 1\n",
    "    \n",
    "    # Generate windowed data\n",
    "    windowed_discharges = []\n",
    "    for discharge in discharges:\n",
    "        windowed_discharges.extend(\n",
    "            discharge.generate_windows(\n",
    "                window_size=window_size, \n",
    "                step=step, \n",
    "                overlap=overlap\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    discharges = windowed_discharges\n",
    "    print(f\"Number of discharges after windowing: {len(discharges)}\")\n",
    "    \n",
    "    # Get discharge shapes and classes for debugging\n",
    "    for i, discharge in enumerate(discharges):\n",
    "        print(f\"Discharge {i} shape: {discharge.shape()}, class: {discharge.disruption_class}\")\n",
    "    \n",
    "    # Convert to model input format\n",
    "    X, y = get_X_y(discharges)\n",
    "    \n",
    "    # Transpose X to have shape (num_discharges, time_steps, features)\n",
    "    X = np.array([np.array(signal).T for signal in X])\n",
    "    y = np.array(y)\n",
    "    \n",
    "    print(f\"X shape: {X.shape}, y shape: {y.shape}\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, shuffle=True, stratify=y\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc10e3c",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Define the CNN-LSTM model architecture with convolutional layers, bidirectional LSTM, attention mechanism, and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ee70b00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:58:44.144071Z",
     "iopub.status.busy": "2025-05-04T17:58:44.143491Z",
     "iopub.status.idle": "2025-05-04T17:58:46.532738Z",
     "shell.execute_reply": "2025-05-04T17:58:46.532208Z",
     "shell.execute_reply.started": "2025-05-04T17:58:44.144050Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"CNN_LSTM_Model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"CNN_LSTM_Model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_conv         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ conv1d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ conv1d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bn1                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │ concat_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ act1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ act1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ maxpool1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ spatial_dropout1… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_bidir          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">57,600</span> │ maxpool1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_bidir[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)         │                   │            │ lstm_bidir[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ maxpool1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ attention_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │ concat[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m1,408\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_7 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m2,304\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_8 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │      \u001b[38;5;34m3,200\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_conv         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ conv1d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ conv1d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ conv1d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bn1                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m) │        \u001b[38;5;34m768\u001b[0m │ concat_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ act1 (\u001b[38;5;33mActivation\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ spatial_dropout1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ act1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ maxpool1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ spatial_dropout1… │\n",
       "│ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_bidir          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m57,600\u001b[0m │ maxpool1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ attention_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ lstm_bidir[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│ (\u001b[38;5;33mAttention\u001b[0m)         │                   │            │ lstm_bidir[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ maxpool1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ attention_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m257\u001b[0m │ concat[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,537</span> (256.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m65,537\u001b[0m (256.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">65,153</span> (254.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m65,153\u001b[0m (254.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    Create a CNN-LSTM model for anomaly detection\n",
    "    \n",
    "    Architecture overview:\n",
    "    1. Input layer accepting time series data with 7 signal types\n",
    "    2. Parallel convolutional layers with different kernel sizes to capture patterns at different scales\n",
    "    3. Batch normalization, activation, and spatial dropout for regularization\n",
    "    4. Bidirectional LSTM layer with attention mechanism\n",
    "    5. Concatenation of CNN and LSTM features\n",
    "    6. Dense output layer with sigmoid activation for binary classification\n",
    "    \n",
    "    Returns compiled model ready for training\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    inputs = Input(shape=(None, 7), name=\"input_layer\")\n",
    "    \n",
    "    # Parallel convolutional layers with different kernel sizes\n",
    "    c3 = Conv1D(64, kernel_size=3, padding='same', activation='relu')(inputs)\n",
    "    c5 = Conv1D(64, kernel_size=5, padding='same', activation='relu')(inputs)\n",
    "    c7 = Conv1D(64, kernel_size=7, padding='same', activation='relu')(inputs)\n",
    "    cnn = concatenate([c3, c5, c7], axis=-1, name=\"concat_conv\")\n",
    "    \n",
    "    # Batch normalization, activation, dropout and pooling\n",
    "    cnn = BatchNormalization(name=\"bn1\")(cnn)\n",
    "    cnn = Activation('relu', name=\"act1\")(cnn)\n",
    "    cnn = SpatialDropout1D(0.3, name=\"spatial_dropout1\")(cnn)\n",
    "    cnn = MaxPooling1D(pool_size=2, name=\"maxpool1\")(cnn)\n",
    "    \n",
    "    # Global features from CNN branch\n",
    "    cnn_branch = GlobalMaxPooling1D(name=\"global_max_pooling\")(cnn)\n",
    "    \n",
    "    # Bidirectional LSTM layer\n",
    "    lstm = Bidirectional(\n",
    "        LSTM(\n",
    "            units=32,\n",
    "            dropout=0.2,\n",
    "            recurrent_dropout=0.2,\n",
    "            kernel_regularizer=l2(1e-4),\n",
    "            return_sequences=True,\n",
    "            name=\"lstm_layer\"\n",
    "        ), name=\"lstm_bidir\"\n",
    "    )(cnn)\n",
    "    \n",
    "    # Attention mechanism\n",
    "    context = Attention()([lstm, lstm])\n",
    "    attn_out = GlobalMaxPooling1D()(context)\n",
    "    \n",
    "    # Merge CNN and attention features\n",
    "    merged = concatenate([cnn_branch, attn_out], name=\"concat\")\n",
    "    \n",
    "    # Output layer\n",
    "    outputs = Dense(1, activation='sigmoid', name=\"output_layer\")(merged)\n",
    "    \n",
    "    # Create and compile model\n",
    "    model = Model(inputs, outputs, name=\"CNN_LSTM_Model\")\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81df6f8a",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Set up training parameters, callbacks for early stopping and learning rate reduction, and other configuration options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b73c2e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T17:58:50.211287Z",
     "iopub.status.busy": "2025-05-04T17:58:50.210731Z",
     "iopub.status.idle": "2025-05-04T17:58:50.217499Z",
     "shell.execute_reply": "2025-05-04T17:58:50.216822Z",
     "shell.execute_reply.started": "2025-05-04T17:58:50.211265Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:\n",
      "  epochs: 100\n",
      "  batch_size: 2\n",
      "  shuffle: True\n",
      "  model_path: cnn_lstm_model.keras\n",
      "  callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n"
     ]
    }
   ],
   "source": [
    "def configure_training(model_path=\"cnn_lstm_model.keras\"):\n",
    "    \"\"\"\n",
    "    Configure training parameters and callbacks\n",
    "    \n",
    "    Returns a dictionary with training configuration\n",
    "    \"\"\"\n",
    "    # Callbacks for training\n",
    "    callbacks = [\n",
    "        # Stop training when validation loss stops improving\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate when validation loss plateaus\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Save the best model\n",
    "        ModelCheckpoint(\n",
    "            model_path,\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Training parameters\n",
    "    training_config = {\n",
    "        'epochs': 100,\n",
    "        'batch_size': 2,\n",
    "        'shuffle': True,\n",
    "        'callbacks': callbacks,\n",
    "        'model_path': model_path\n",
    "    }\n",
    "    \n",
    "    return training_config\n",
    "\n",
    "# Get training configuration\n",
    "training_config = configure_training()\n",
    "print(\"Training configuration:\")\n",
    "for k, v in training_config.items():\n",
    "    if k != 'callbacks':\n",
    "        print(f\"  {k}: {v}\")\n",
    "print(\"  callbacks: EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ada1eb",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "Train the model with the prepared data and visualize the training process with loss and accuracy plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b81865",
   "metadata": {},
   "source": [
    "## Visualization and Evaluation\n",
    "\n",
    "Evaluate the model performance on validation data and create visualizations to understand the model's behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4669e64c",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-04T17:59:48.332656Z",
     "iopub.status.idle": "2025-05-04T17:59:48.332884Z",
     "shell.execute_reply": "2025-05-04T17:59:48.332787Z",
     "shell.execute_reply.started": "2025-05-04T17:59:48.332777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Make predictions and calculate some metrics\n",
    "y_pred_proba = model.predict(X_val)\n",
    "y_pred = (y_pred_proba > 0.5).astype(\"int32\")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "classes = ['Normal', 'Anomaly']\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "# Add text annotations to confusion matrix\n",
    "thresh = cm.max() / 2.\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03522aeb",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n",
    "Save the trained model to an .h5 file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c79a9a51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T18:00:16.874283Z",
     "iopub.status.busy": "2025-05-04T18:00:16.873792Z",
     "iopub.status.idle": "2025-05-04T18:00:16.955324Z",
     "shell.execute_reply": "2025-05-04T18:00:16.954688Z",
     "shell.execute_reply.started": "2025-05-04T18:00:16.874257Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to cnn_lstm_model.keras\n"
     ]
    }
   ],
   "source": [
    "model_path = training_config['model_path']\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Function to load the model later\n",
    "def load_model(model_path='cnn_lstm_model.keras'):\n",
    "    \"\"\"Load a saved model\"\"\"\n",
    "    if model_path.endswith('_pickle.h5'):\n",
    "        # Load using pickle\n",
    "        with open(model_path, 'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "    else:\n",
    "        # Load using Keras\n",
    "        loaded_model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    return loaded_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2f0d3d",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We've successfully built and trained a CNN-LSTM model for anomaly detection in time series data from discharge experiments. The model combines:\n",
    "\n",
    "1. Convolutional layers with multiple kernel sizes to capture local patterns at different scales\n",
    "2. Bidirectional LSTM with attention mechanism to capture temporal dependencies\n",
    "3. Dropout and batch normalization for regularization to prevent overfitting\n",
    "\n",
    "The model can be deployed to detect anomalies in new discharge data. For production use, you might want to:\n",
    "\n",
    "1. Perform hyperparameter tuning to optimize performance\n",
    "2. Implement cross-validation for more robust evaluation\n",
    "3. Consider data augmentation techniques for small datasets\n",
    "4. Add explainability methods to understand model decisions"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7327849,
     "sourceId": 11675672,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
